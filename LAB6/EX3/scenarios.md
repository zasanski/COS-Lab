### Test Scenario A: One Producer and One Consumer

* **Setup:** 1 `master` + 1 `slave`.
* **Behavior:** `Master` sends tasks one-by-one; `slave` processes each task sequentially and returns results. Flow is orderly.


### Test Scenario B: One Producer and Several Consumers

* **Setup:** 1 `master` + multiple `slave`s.
* **Behavior:** `Master` fills `TASK_QUEUE` quickly. `Slave`s compete for tasks, distributing the workload. Results return out of order, showing load balancing.


### Test Scenario C: Several Producers and One Consumer

* **Setup:** Multiple `master`s + 1 `slave`.
* **Observed Behavior:** All `master`s push tasks into the shared `TASK_QUEUE`. The single `slave` pulls and processes tasks from various producers. Results are sent back to the shared `RESULT_QUEUE`. The `master` processes will each read a total number of results equal to the tasks they sent, but these results will be a mix from all producers. Each master will display the `producer_pid` contained in the received `result_t` struct, which will often be different from its own PID, showing results from other producers.


### Test Scenario D: Several Producers and Several Consumers

* **Setup:** Multiple `master`s + multiple `slave`s.
* **Observed Behavior:** A complex, fully concurrent system. Tasks from multiple producers are distributed among multiple consumers. All `master` processes will read results from the shared `RESULT_QUEUE`, receiving a mix of results from tasks they generated and tasks generated by other masters. The processing and result collection will appear highly mixed and asynchronous across all terminals. We see masters displaying results whose `producer_pid` doesn't match their own.
